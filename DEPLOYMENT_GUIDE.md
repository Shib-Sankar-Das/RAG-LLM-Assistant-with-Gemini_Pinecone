# ğŸš€ RAG LLM Assistant - Streamlit Cloud Deployment Guide

## âœ… Migration Complete: ChromaDB âœ Pinecone

Your RAG LLM Assistant has been successfully migrated from ChromaDB to Pinecone cloud database and is now **ready for Streamlit Cloud deployment**!

### ğŸ¯ What Was Changed

#### âŒ Removed (ChromaDB Issues)
- **ChromaDB**: 67MB local files blocked Streamlit Cloud deployment
- **Local Storage**: `chroma_db/` folder and persistence directories
- **Package Conflicts**: Incompatible ChromaDB dependencies

#### âœ… Added (Pinecone Solution)
- **Pinecone Cloud Database**: Unlimited storage, no file size limits
- **Namespace Support**: Persistent vs Temporary storage modes
- **Compatible Packages**: Working pinecone==6.0.0 + langchain-pinecone==0.2.11

---

## ğŸ—ï¸ Project Architecture

### ğŸ“ Final Project Structure
```
RAG-LLM-Assistant/
â”œâ”€â”€ app.py                    # Main Streamlit application
â”œâ”€â”€ requirements.txt          # Deployment dependencies (Pinecone-only)
â”œâ”€â”€ .env.example             # Environment template
â”œâ”€â”€ README.md                # Project documentation
â”œâ”€â”€ DEPLOYMENT_GUIDE.md      # This deployment guide
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py            # Pinecone-only configuration
â”‚   â”œâ”€â”€ components/          # UI components
â”‚   â”‚   â”œâ”€â”€ sidebar.py       # Database config (Pinecone modes)
â”‚   â”‚   â”œâ”€â”€ chat_tab.py      # Chat interface
â”‚   â”‚   â”œâ”€â”€ pdf_upload_tab.py # PDF processing
â”‚   â”‚   â””â”€â”€ web_scraping_tab.py # Web scraping
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ rag_system.py    # Pinecone-only RAG system
â”‚   â”‚   â”œâ”€â”€ llm.py           # Google Gemini integration
â”‚   â”‚   â””â”€â”€ document_processor.py # Document processing
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ ui_helpers.py    # UI utilities
```

### ğŸ”§ Key Technical Components

1. **Vector Database**: Pinecone Cloud (namespace-based storage)
2. **LLM**: Google Gemini 2.5 Pro
3. **Embeddings**: HuggingFace sentence-transformers
4. **Framework**: Streamlit + LangChain
5. **Storage Modes**: 
   - `Persistent` â†’ namespace="persistent" 
   - `Temporary` â†’ namespace="temporary"

---

## ğŸš€ Streamlit Cloud Deployment Steps

### 1. ğŸ“ Push Code to GitHub
```bash
# Initialize git repository (if not already done)
git init
git add .
git commit -m "Initial commit: Pinecone-ready RAG LLM Assistant"

# Push to GitHub
git remote add origin https://github.com/YOUR_USERNAME/rag-llm-assistant.git
git branch -M main
git push -u origin main
```

### 2. ğŸŒ Deploy to Streamlit Cloud

1. **Go to**: [https://share.streamlit.io](https://share.streamlit.io)
2. **Connect GitHub**: Link your GitHub account
3. **New App**: Click "New app"
4. **Repository**: Select your `rag-llm-assistant` repo
5. **Main file path**: `app.py`
6. **Advanced settings** â†’ **Python version**: `3.11` or `3.12`

### 3. ğŸ” Configure Environment Variables

In Streamlit Cloud **Advanced settings** â†’ **Secrets**, add:

```toml
# Google AI API Key
GOOGLE_API_KEY = "your_google_api_key_here"

# Pinecone Configuration
PINECONE_API_KEY = "your_pinecone_api_key_here"
PINECONE_INDEX_NAME = "rag-assistant"
PINECONE_ENVIRONMENT = "us-east-1"
```

### 4. ğŸ¯ Deploy Application
- Click **"Deploy!"**
- Wait for deployment (~2-3 minutes)
- Your app will be live at: `https://your-app-name.streamlit.app`

---

## ğŸ”§ Environment Setup

### ğŸ“‹ Required API Keys

1. **Google AI Studio API Key**:
   - Go to: [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)
   - Create new API key
   - Copy for `GOOGLE_API_KEY`

2. **Pinecone API Key**:
   - Go to: [https://www.pinecone.io](https://www.pinecone.io)
   - Sign up/Login â†’ Dashboard
   - Copy API key for `PINECONE_API_KEY`
   - Index name: `rag-assistant` (auto-created)

### ğŸ  Local Development Setup

```bash
# 1. Clone repository
git clone https://github.com/YOUR_USERNAME/rag-llm-assistant.git
cd rag-llm-assistant

# 2. Create virtual environment
python -m venv venv
# Windows:
venv\\Scripts\\activate
# macOS/Linux:
source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Setup environment variables
cp .env.example .env
# Edit .env with your API keys

# 5. Run application
streamlit run app.py
```

---

## ğŸ“¦ Package Dependencies

### ğŸ¯ Core Production Dependencies
```
streamlit==1.39.0           # Web framework
python-dotenv==1.0.1        # Environment management
google-generativeai==0.8.3  # Google Gemini LLM
langchain==0.3.10          # LangChain framework
langchain-huggingface==0.1.3 # HuggingFace embeddings
pinecone[asyncio]==6.0.0    # Pinecone cloud database
langchain-pinecone==0.2.11  # Pinecone-LangChain integration
sentence-transformers==3.3.0 # Embeddings model
PyPDF2==3.0.1              # PDF processing
requests==2.32.4           # HTTP requests
beautifulsoup4==4.12.3     # Web scraping
```

### âœ… Package Compatibility
- **âœ… Tested**: All packages verified working together
- **âœ… Cloud Ready**: No local storage dependencies
- **âœ… Version Locked**: Stable versions for reliable deployment

---

## ğŸ® Usage Guide

### ğŸ“Š Database Modes

1. **Persistent Mode** (Default):
   - Data stored permanently in Pinecone cloud
   - Survives application restarts
   - Shared across sessions
   - Namespace: `"persistent"`

2. **Temporary Mode**:
   - Session-only storage
   - Cleared when switching modes
   - Perfect for testing
   - Namespace: `"temporary"`

### ğŸŒ Web Scraping
- Enter any website URL
- Automatic content extraction
- Smart text chunking
- Vector embedding storage

### ğŸ“„ PDF Upload
- Upload multiple PDF files
- Text extraction and processing
- Chapter-aware chunking
- Searchable knowledge base

### ğŸ’¬ Chat Interface
- Natural language queries
- Context-aware responses
- Source document references
- Real-time retrieval

---

## ğŸ‰ Deployment Benefits

### â˜ï¸ Cloud-Native Architecture
- **No File Size Limits**: Pinecone handles unlimited data
- **Global Accessibility**: Cloud database accessible worldwide
- **Auto-Scaling**: Pinecone scales automatically
- **99.9% Uptime**: Enterprise-grade reliability

### ğŸš€ Performance Advantages
- **Fast Queries**: Optimized vector search
- **Low Latency**: Global edge locations
- **Efficient Storage**: Compressed vector storage
- **Real-time Updates**: Instant data synchronization

### ğŸ’° Cost-Effective
- **Free Tier**: Pinecone starter plan (100K vectors)
- **Pay-as-Scale**: Only pay for what you use
- **No Infrastructure**: No server management needed
- **Streamlit Free**: Free hosting for public apps

---

## ğŸ” Troubleshooting

### Common Issues & Solutions

**Issue**: Package import errors
```bash
# Solution: Reinstall with exact versions
pip uninstall pinecone langchain-pinecone -y
pip install pinecone[asyncio]==6.0.0 langchain-pinecone==0.2.11
```

**Issue**: Plugin compatibility errors ("This assistant plugin version is not compatible")
```bash
# Solution: Remove incompatible plugins
pip uninstall pinecone-plugin-assistant pinecone-plugin-inference -y
# These plugins are deprecated and conflict with Pinecone 6.0.0
```

**Issue**: API key errors
- Verify keys in Streamlit Cloud secrets
- Check key permissions in respective dashboards
- Ensure no extra spaces in key values

**Issue**: Index not found
- Pinecone index auto-creates on first use
- Verify `PINECONE_INDEX_NAME="rag-assistant"`
- Check Pinecone dashboard for index status

---

## âœ¨ Success!

Your RAG LLM Assistant is now:
- âœ… **Cloud-Ready**: No local storage dependencies
- âœ… **Scalable**: Pinecone cloud database
- âœ… **Deployable**: Compatible with Streamlit Cloud
- âœ… **Production-Grade**: Stable package versions
- âœ… **Cost-Effective**: Free tier available

**Ready to deploy to Streamlit Cloud!** ğŸš€
